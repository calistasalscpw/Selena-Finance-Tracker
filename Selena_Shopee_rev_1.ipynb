{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/calistasalscpw/Selena-Finance-Tracker/blob/main/Selena_Shopee_rev_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Ux0RNBRsPJT"
   },
   "source": [
    "#Capstone Project - Selena (Shopee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUsZwki3sRR1"
   },
   "source": [
    "**Proses Analisis oleh Model ML (Menggunakan File .pkl)**\n",
    "\n",
    "- **Backend kemudian memuat model ML yang sudah dilatih (disimpan dalam format .pkl) menggunakan library Pickle di Python.**\n",
    "- Model ML ini memproses data transaksi pengguna yang sudah diambil dari database untuk melakukan beberapa tugas analisis:\n",
    "    - Arus Kas: Mengidentifikasi pola pemasukan dan pengeluaran.\n",
    "    - Saran Keuangan: Berdasarkan analisis tren keuangan pengguna, model bisa memberikan saran, misalnya mengurangi pengeluaran di kategori tertentu.\n",
    "    - Deteksi Anomali Pengeluaran: Model ML mendeteksi adanya transaksi atau pengeluaran yang tidak biasa atau mencurigakan.\n",
    "\n",
    "Pengembalian Hasil Analisis ke Backend (ML ke CC)\n",
    "\n",
    "- Model ML menghasilkan output analisis, seperti rekomendasi keuangan atau deteksi anomali, yang dikonversi ke **format JSON**.\n",
    "- Backend menerima hasil ini dan menggabungkannya menjadi satu respons JSON yang siap dikirim ke aplikasi mobile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNcbKYMosUIa"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CxdRXDE2HvA6"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdFg0ewgsY7Q"
   },
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AMq397uSSZzG"
   },
   "outputs": [],
   "source": [
    "#FUNGSI UNTUK PREPROCESSING DATA\n",
    "\n",
    "def preprocess_data(data_path):\n",
    "  # Membaca file dataset\n",
    "  read_file = pd.read_excel(data_path)\n",
    "  read_file.to_csv(\"./data/dataset.csv\", index=None, header=True)\n",
    "  df = pd.DataFrame(pd.read_csv(\"./data/dataset.csv\"))\n",
    "\n",
    "  # Mengambil kolom yang dibutuhkan\n",
    "  data_filtered = df[['Waktu Pesanan Selesai', 'Total Pembayaran']].copy()\n",
    "\n",
    "  # Menghapus titik dari kolom 'Total Pembayaran'\n",
    "  data_filtered['Total Pembayaran'] = data_filtered['Total Pembayaran'].astype(str).str.replace('.', '', regex=False)\n",
    "\n",
    "  # Mengkonversi tipe data\n",
    "  data_filtered['Total Pembayaran'] = pd.to_numeric(data_filtered['Total Pembayaran'])\n",
    "  data_filtered['Waktu Pesanan Selesai'] = pd.to_datetime(data_filtered['Waktu Pesanan Selesai']).dt.date\n",
    "\n",
    "  # Menghapus pesanan yang dibatalkan/tidak selesai\n",
    "  data_final = data_filtered[data_filtered['Total Pembayaran'] != 0]\n",
    "\n",
    "  # Assign value variabel time dan series\n",
    "  time = data_final['Waktu Pesanan Selesai'].tolist()\n",
    "  series = data_final['Total Pembayaran'].tolist()\n",
    "\n",
    "  return time, series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eC7HObkxspQJ"
   },
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "erBMa3xVQuPG"
   },
   "outputs": [],
   "source": [
    "### Inisiasi variabel global ###\n",
    "\n",
    "DATA_PATH = './data/Order.completed.20240903_20241003.xlsx'\n",
    "TIME, SERIES = preprocess_data(DATA_PATH)\n",
    "\n",
    "# Model\n",
    "SPLIT_TIME = 90\n",
    "WINDOW_SIZE = 7\n",
    "BATCH_SIZE = 4\n",
    "SHUFFLE_BUFFER_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6X6xH_estQ8"
   },
   "source": [
    "## Defining Functions\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2guj8LCiqEqb"
   },
   "outputs": [],
   "source": [
    "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(time[start:end], series[start:end], format)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.grid(True)\n",
    "    plt.gca().xaxis.set_major_formatter(DateFormatter(\"%Y-%m-%d\"))  # Menyesuaikan format tanggal\n",
    "    plt.gcf().autofmt_xdate()  # Memutar tanggal agar tidak bertabrakan\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_2e9OQOO6ZTo"
   },
   "outputs": [],
   "source": [
    "def train_val_split(time, series):\n",
    "    \"\"\"Split time series into train and validation sets\"\"\"\n",
    "    time_train = time[:SPLIT_TIME]\n",
    "    series_train = series[:SPLIT_TIME]\n",
    "    time_valid = time[SPLIT_TIME:]\n",
    "    series_valid = series[SPLIT_TIME:]\n",
    "\n",
    "    return time_train, series_train, time_valid, series_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "szm59VQi7B7a"
   },
   "outputs": [],
   "source": [
    "def create_windowed_dataset(series, window_size=WINDOW_SIZE, batch_size=BATCH_SIZE, shuffle_buffer=SHUFFLE_BUFFER_SIZE):\n",
    "    \"\"\"\n",
    "    Membuat dataset dalam bentuk windowed untuk time series.\n",
    "\n",
    "    Parameters:\n",
    "    - series: Data time series dalam bentuk array atau list.\n",
    "    - window_size: Jumlah langkah dalam satu jendela input.\n",
    "    - batch_size: Jumlah data yang diproses dalam satu batch.\n",
    "    - shuffle_buffer: Ukuran buffer untuk pengacakan data.\n",
    "\n",
    "    Returns:\n",
    "    - dataset: Dataset dengan pasangan input-output berdasarkan window size.\n",
    "    \"\"\"\n",
    "\n",
    "    # Konversi data series ke dalam dataset tensorflow\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "\n",
    "    # Membuat window untuk setiap sample\n",
    "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "\n",
    "    # Konversi setiap window ke dalam bentuk batch\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
    "\n",
    "    # Memisahkan window menjadi input (features) dan output (label)\n",
    "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "\n",
    "    # Mengacak data menggunakan shuffle buffer\n",
    "    dataset = dataset.shuffle(buffer_size=shuffle_buffer)\n",
    "\n",
    "    # Membuat batch data\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "RhARga4i76Gx"
   },
   "outputs": [],
   "source": [
    "def create_uncompiled_model():\n",
    "    \"\"\"Define uncompiled model\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: uncompiled model\n",
    "    \"\"\"\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.Input(shape=(WINDOW_SIZE, 1)),\n",
    "        tf.keras.layers.Conv1D(filters=16, kernel_size=3, strides=1, padding='causal', activation='relu'),\n",
    "        tf.keras.layers.LSTM(16, return_sequences=True),\n",
    "        tf.keras.layers.LSTM(8),\n",
    "        tf.keras.layers.Dense(8, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tB5E3fSL8_fC"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"Creates and compiles the model\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: compiled model\n",
    "    \"\"\"\n",
    "\n",
    "    model = create_uncompiled_model()\n",
    "\n",
    "    model.compile(loss = tf.keras.losses.Huber(),\n",
    "                  optimizer = tf.keras.optimizers.SGD(momentum=0.9),\n",
    "                  metrics=[\"mae\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3EHqdFhN5SmG"
   },
   "outputs": [],
   "source": [
    "time_train, series_train, time_valid, series_valid = train_val_split(TIME, SERIES)\n",
    "series_train_windowed = create_windowed_dataset(series_train)\n",
    "\n",
    "# model\n",
    "uncompiled_model = create_uncompiled_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rdZHW4188uLP",
    "outputId": "7319b6d0-16e6-449c-ab22-f31e6d6f67fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your current architecture is compatible with the windowed dataset! :)\n",
      "predictions have shape: (4, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    }
   ],
   "source": [
    "example_batch = series_train_windowed.take(1)\n",
    "\n",
    "try:\n",
    "\tpredictions = uncompiled_model.predict(example_batch, verbose=False)\n",
    "except:\n",
    "\tprint(\"Your model is not compatible with the dataset you defined earlier. Check that the loss function and last layer are compatible with one another.\")\n",
    "else:\n",
    "\tprint(\"Your current architecture is compatible with the windowed dataset! :)\")\n",
    "\tprint(f\"predictions have shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qw0bUvqC871W"
   },
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3nGZ04qB9MGm",
    "outputId": "19e6ddbd-4229-4259-c63d-49f8d14a634f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 136782.8594 - mae: 136783.3594 - learning_rate: 1.0000e-08\n",
      "Epoch 2/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 159255.5312 - mae: 159256.0312 - learning_rate: 1.1220e-08\n",
      "Epoch 3/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 144413.4531 - mae: 144413.9531 - learning_rate: 1.2589e-08\n",
      "Epoch 4/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 128240.8516 - mae: 128241.3516 - learning_rate: 1.4125e-08\n",
      "Epoch 5/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 129213.1172 - mae: 129213.6172 - learning_rate: 1.5849e-08\n",
      "Epoch 6/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 149128.1094 - mae: 149128.6094 - learning_rate: 1.7783e-08\n",
      "Epoch 7/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 141336.0938 - mae: 141336.5938 - learning_rate: 1.9953e-08\n",
      "Epoch 8/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 196406.4844 - mae: 196406.9844 - learning_rate: 2.2387e-08\n",
      "Epoch 9/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 155372.0625 - mae: 155372.5625 - learning_rate: 2.5119e-08\n",
      "Epoch 10/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 131015.2656 - mae: 131015.7656 - learning_rate: 2.8184e-08\n",
      "Epoch 11/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 140309.1406 - mae: 140309.6406 - learning_rate: 3.1623e-08\n",
      "Epoch 12/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 159371.0312 - mae: 159371.5312 - learning_rate: 3.5481e-08\n",
      "Epoch 13/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 143828.7188 - mae: 143829.2188 - learning_rate: 3.9811e-08\n",
      "Epoch 14/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 156032.7500 - mae: 156033.2500 - learning_rate: 4.4668e-08\n",
      "Epoch 15/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 140690.3906 - mae: 140690.8906 - learning_rate: 5.0119e-08\n",
      "Epoch 16/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 149008.3594 - mae: 149008.8594 - learning_rate: 5.6234e-08\n",
      "Epoch 17/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 128675.6016 - mae: 128676.0938 - learning_rate: 6.3096e-08\n",
      "Epoch 18/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 135106.2500 - mae: 135106.7500 - learning_rate: 7.0795e-08\n",
      "Epoch 19/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 144932.7656 - mae: 144933.2656 - learning_rate: 7.9433e-08\n",
      "Epoch 20/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 146986.1875 - mae: 146986.6875 - learning_rate: 8.9125e-08\n",
      "Epoch 21/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 139850.5469 - mae: 139851.0469 - learning_rate: 1.0000e-07\n",
      "Epoch 22/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 154570.0938 - mae: 154570.5938 - learning_rate: 1.1220e-07\n",
      "Epoch 23/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 133661.0156 - mae: 133661.5156 - learning_rate: 1.2589e-07\n",
      "Epoch 24/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 143216.3906 - mae: 143216.8906 - learning_rate: 1.4125e-07\n",
      "Epoch 25/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 129575.1406 - mae: 129575.6406 - learning_rate: 1.5849e-07\n",
      "Epoch 26/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 123788.7969 - mae: 123789.2969 - learning_rate: 1.7783e-07\n",
      "Epoch 27/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 134886.0625 - mae: 134886.5625 - learning_rate: 1.9953e-07\n",
      "Epoch 28/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 147819.8281 - mae: 147820.3281 - learning_rate: 2.2387e-07\n",
      "Epoch 29/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 136644.9375 - mae: 136645.4375 - learning_rate: 2.5119e-07\n",
      "Epoch 30/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 148547.9062 - mae: 148548.4062 - learning_rate: 2.8184e-07\n",
      "Epoch 31/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 128015.2344 - mae: 128015.7344 - learning_rate: 3.1623e-07\n",
      "Epoch 32/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 146994.4844 - mae: 146994.9844 - learning_rate: 3.5481e-07\n",
      "Epoch 33/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 133964.0156 - mae: 133964.5156 - learning_rate: 3.9811e-07\n",
      "Epoch 34/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 139830.5000 - mae: 139831.0000 - learning_rate: 4.4668e-07\n",
      "Epoch 35/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 126052.2734 - mae: 126052.7734 - learning_rate: 5.0119e-07\n",
      "Epoch 36/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 173265.0938 - mae: 173265.5938 - learning_rate: 5.6234e-07\n",
      "Epoch 37/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 134713.5781 - mae: 134714.0781 - learning_rate: 6.3096e-07\n",
      "Epoch 38/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 164961.0625 - mae: 164961.5625 - learning_rate: 7.0795e-07\n",
      "Epoch 39/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 152494.8906 - mae: 152495.3906 - learning_rate: 7.9433e-07\n",
      "Epoch 40/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 159829.4062 - mae: 159829.8906 - learning_rate: 8.9125e-07\n",
      "Epoch 41/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 130968.9062 - mae: 130969.4062 - learning_rate: 1.0000e-06\n",
      "Epoch 42/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 145677.9062 - mae: 145678.4062 - learning_rate: 1.1220e-06\n",
      "Epoch 43/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 174843.6875 - mae: 174844.1875 - learning_rate: 1.2589e-06\n",
      "Epoch 44/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 133561.4531 - mae: 133561.9531 - learning_rate: 1.4125e-06\n",
      "Epoch 45/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 131473.3438 - mae: 131473.8438 - learning_rate: 1.5849e-06\n",
      "Epoch 46/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 132474.7031 - mae: 132475.2031 - learning_rate: 1.7783e-06\n",
      "Epoch 47/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 175640.2656 - mae: 175640.7656 - learning_rate: 1.9953e-06\n",
      "Epoch 48/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 148197.7188 - mae: 148198.2188 - learning_rate: 2.2387e-06\n",
      "Epoch 49/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 139856.1562 - mae: 139856.6562 - learning_rate: 2.5119e-06\n",
      "Epoch 50/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 143037.8438 - mae: 143038.3438 - learning_rate: 2.8184e-06\n",
      "Epoch 51/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 130625.3047 - mae: 130625.8047 - learning_rate: 3.1623e-06\n",
      "Epoch 52/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 156480.9688 - mae: 156481.4688 - learning_rate: 3.5481e-06\n",
      "Epoch 53/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 162540.5312 - mae: 162541.0312 - learning_rate: 3.9811e-06\n",
      "Epoch 54/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 130341.7031 - mae: 130342.2031 - learning_rate: 4.4668e-06\n",
      "Epoch 55/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 139586.2344 - mae: 139586.7344 - learning_rate: 5.0119e-06\n",
      "Epoch 56/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 128586.3203 - mae: 128586.8281 - learning_rate: 5.6234e-06\n",
      "Epoch 57/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 156220.0469 - mae: 156220.5469 - learning_rate: 6.3096e-06\n",
      "Epoch 58/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 169576.9844 - mae: 169577.4844 - learning_rate: 7.0795e-06\n",
      "Epoch 59/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 141024.3281 - mae: 141024.8281 - learning_rate: 7.9433e-06\n",
      "Epoch 60/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 150249.5312 - mae: 150250.0312 - learning_rate: 8.9125e-06\n",
      "Epoch 61/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 144275.2031 - mae: 144275.7031 - learning_rate: 1.0000e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 137686.4844 - mae: 137686.9844 - learning_rate: 1.1220e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 143170.2500 - mae: 143170.7500 - learning_rate: 1.2589e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 129650.8750 - mae: 129651.3750 - learning_rate: 1.4125e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 151671.7656 - mae: 151672.2656 - learning_rate: 1.5849e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 164703.7344 - mae: 164704.2344 - learning_rate: 1.7783e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 150744.6250 - mae: 150745.1250 - learning_rate: 1.9953e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 136222.7656 - mae: 136223.2656 - learning_rate: 2.2387e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 140934.1094 - mae: 140934.6094 - learning_rate: 2.5119e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 126465.9609 - mae: 126466.4609 - learning_rate: 2.8184e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 133179.6562 - mae: 133180.1562 - learning_rate: 3.1623e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 149023.2031 - mae: 149023.7031 - learning_rate: 3.5481e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 143632.7031 - mae: 143633.2031 - learning_rate: 3.9811e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 154919.2500 - mae: 154919.7500 - learning_rate: 4.4668e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 145233.1875 - mae: 145233.6875 - learning_rate: 5.0119e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 196997.9688 - mae: 196998.4688 - learning_rate: 5.6234e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 167046.7500 - mae: 167047.2500 - learning_rate: 6.3096e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 144761.3594 - mae: 144761.8594 - learning_rate: 7.0795e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 143333.0781 - mae: 143333.5781 - learning_rate: 7.9433e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 134835.1875 - mae: 134835.6875 - learning_rate: 8.9125e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 134152.3281 - mae: 134152.8281 - learning_rate: 1.0000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 144230.5000 - mae: 144231.0000 - learning_rate: 1.1220e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 136300.5938 - mae: 136301.0938 - learning_rate: 1.2589e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 160649.1562 - mae: 160649.6562 - learning_rate: 1.4125e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 151360.1562 - mae: 151360.6562 - learning_rate: 1.5849e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 134599.5469 - mae: 134600.0469 - learning_rate: 1.7783e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 158294.2500 - mae: 158294.7500 - learning_rate: 1.9953e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 139895.1406 - mae: 139895.6406 - learning_rate: 2.2387e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 150416.5312 - mae: 150417.0312 - learning_rate: 2.5119e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 130044.3203 - mae: 130044.8281 - learning_rate: 2.8184e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 160567.2344 - mae: 160567.7344 - learning_rate: 3.1623e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 128384.7422 - mae: 128385.2344 - learning_rate: 3.5481e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 149124.7656 - mae: 149125.2656 - learning_rate: 3.9811e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 134755.4531 - mae: 134755.9531 - learning_rate: 4.4668e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 144169.2188 - mae: 144169.7188 - learning_rate: 5.0119e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 147451.9219 - mae: 147452.4219 - learning_rate: 5.6234e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 136737.9844 - mae: 136738.4844 - learning_rate: 6.3096e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 140010.1719 - mae: 140010.6719 - learning_rate: 7.0795e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 142380.2969 - mae: 142380.7969 - learning_rate: 7.9433e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 149823.9062 - mae: 149824.4062 - learning_rate: 8.9125e-04\n"
     ]
    }
   ],
   "source": [
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-8 * 10**(epoch / 20))\n",
    "\n",
    "history = model.fit(series_train_windowed, epochs=100, callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xe-uVu8w9QG2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
