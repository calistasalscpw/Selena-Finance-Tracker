{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/calistasalscpw/Selena-Finance-Tracker/blob/main/Selena_Shopee_rev_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Capstone Project - Selena (Shopee)"
      ],
      "metadata": {
        "id": "7Ux0RNBRsPJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Proses Analisis oleh Model ML (Menggunakan File .pkl)**\n",
        "\n",
        "- **Backend kemudian memuat model ML yang sudah dilatih (disimpan dalam format .pkl) menggunakan library Pickle di Python.**\n",
        "- Model ML ini memproses data transaksi pengguna yang sudah diambil dari database untuk melakukan beberapa tugas analisis:\n",
        "    - Arus Kas: Mengidentifikasi pola pemasukan dan pengeluaran.\n",
        "    - Saran Keuangan: Berdasarkan analisis tren keuangan pengguna, model bisa memberikan saran, misalnya mengurangi pengeluaran di kategori tertentu.\n",
        "    - Deteksi Anomali Pengeluaran: Model ML mendeteksi adanya transaksi atau pengeluaran yang tidak biasa atau mencurigakan.\n",
        "\n",
        "Pengembalian Hasil Analisis ke Backend (ML ke CC)\n",
        "\n",
        "- Model ML menghasilkan output analisis, seperti rekomendasi keuangan atau deteksi anomali, yang dikonversi ke **format JSON**.\n",
        "- Backend menerima hasil ini dan menggabungkannya menjadi satu respons JSON yang siap dikirim ke aplikasi mobile."
      ],
      "metadata": {
        "id": "ZUsZwki3sRR1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "bNcbKYMosUIa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxdRXDE2HvA6"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.dates import DateFormatter\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing Data"
      ],
      "metadata": {
        "id": "OdFg0ewgsY7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#FUNGSI UNTUK PREPROCESSING DATA\n",
        "\n",
        "def preprocess_data(data_path):\n",
        "  # Membaca file dataset\n",
        "  read_file = pd.read_excel(data_path)\n",
        "  read_file.to_csv(\"./data/dataset.csv\", index=None, header=True)\n",
        "  df = pd.DataFrame(pd.read_csv(\"./data/dataset.csv\"))\n",
        "\n",
        "  # Mengambil kolom yang dibutuhkan\n",
        "  data_filtered = df[['Waktu Pesanan Selesai', 'Total Pembayaran']].copy()\n",
        "\n",
        "  # Menghapus titik dari kolom 'Total Pembayaran'\n",
        "  data_filtered['Total Pembayaran'] = data_filtered['Total Pembayaran'].astype(str).str.replace('.', '', regex=False)\n",
        "\n",
        "  # Mengkonversi tipe data\n",
        "  data_filtered['Total Pembayaran'] = pd.to_numeric(data_filtered['Total Pembayaran'])\n",
        "  data_filtered['Waktu Pesanan Selesai'] = pd.to_datetime(data_filtered['Waktu Pesanan Selesai']).dt.date\n",
        "\n",
        "  # Menghapus pesanan yang dibatalkan/tidak selesai\n",
        "  data_final = data_filtered[data_filtered['Total Pembayaran'] != 0]\n",
        "\n",
        "  # Assign value variabel time dan series\n",
        "  time = data_final['Waktu Pesanan Selesai'].tolist()\n",
        "  series = data_final['Total Pembayaran'].tolist()\n",
        "\n",
        "  return time, series"
      ],
      "metadata": {
        "id": "AMq397uSSZzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global Variables"
      ],
      "metadata": {
        "id": "eC7HObkxspQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Inisiasi variabel global ###\n",
        "\n",
        "DATA_PATH = './data/dataset.xlsx'\n",
        "TIME, SERIES = preprocess_data(DATA_PATH)\n",
        "\n",
        "# Model\n",
        "SPLIT_TIME = 90\n",
        "WINDOW_SIZE = 7\n",
        "BATCH_SIZE = 4\n",
        "SHUFFLE_BUFFER_SIZE = 100"
      ],
      "metadata": {
        "id": "erBMa3xVQuPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Functions\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Y6X6xH_estQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    plt.plot(time[start:end], series[start:end], format)\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.grid(True)\n",
        "    plt.gca().xaxis.set_major_formatter(DateFormatter(\"%Y-%m-%d\"))  # Menyesuaikan format tanggal\n",
        "    plt.gcf().autofmt_xdate()  # Memutar tanggal agar tidak bertabrakan\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2guj8LCiqEqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_split(time, series):\n",
        "    \"\"\"Split time series into train and validation sets\"\"\"\n",
        "    time_train = time[:SPLIT_TIME]\n",
        "    series_train = series[:SPLIT_TIME]\n",
        "    time_valid = time[SPLIT_TIME:]\n",
        "    series_valid = series[SPLIT_TIME:]\n",
        "\n",
        "    return time_train, series_train, time_valid, series_valid"
      ],
      "metadata": {
        "id": "_2e9OQOO6ZTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_windowed_dataset(series, window_size=WINDOW_SIZE, batch_size=BATCH_SIZE, shuffle_buffer=SHUFFLE_BUFFER_SIZE):\n",
        "    \"\"\"\n",
        "    Membuat dataset dalam bentuk windowed untuk time series.\n",
        "\n",
        "    Parameters:\n",
        "    - series: Data time series dalam bentuk array atau list.\n",
        "    - window_size: Jumlah langkah dalam satu jendela input.\n",
        "    - batch_size: Jumlah data yang diproses dalam satu batch.\n",
        "    - shuffle_buffer: Ukuran buffer untuk pengacakan data.\n",
        "\n",
        "    Returns:\n",
        "    - dataset: Dataset dengan pasangan input-output berdasarkan window size.\n",
        "    \"\"\"\n",
        "\n",
        "    # Konversi data series ke dalam dataset tensorflow\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "\n",
        "    # Membuat window untuk setiap sample\n",
        "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "\n",
        "    # Konversi setiap window ke dalam bentuk batch\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
        "\n",
        "    # Memisahkan window menjadi input (features) dan output (label)\n",
        "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
        "\n",
        "    # Mengacak data menggunakan shuffle buffer\n",
        "    dataset = dataset.shuffle(buffer_size=shuffle_buffer)\n",
        "\n",
        "    # Membuat batch data\n",
        "    dataset = dataset.batch(batch_size).prefetch(1)\n",
        "\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "szm59VQi7B7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_uncompiled_model():\n",
        "    \"\"\"Define uncompiled model\n",
        "\n",
        "    Returns:\n",
        "        tf.keras.Model: uncompiled model\n",
        "    \"\"\"\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.Input(shape=(WINDOW_SIZE, 1)),\n",
        "        tf.keras.layers.Conv1D(filters=16, kernel_size=3, strides=1, padding='causal', activation='relu'),\n",
        "        tf.keras.layers.LSTM(16, return_sequences=True),\n",
        "        tf.keras.layers.LSTM(8),\n",
        "        tf.keras.layers.Dense(8, activation='relu'),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "RhARga4i76Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    \"\"\"Creates and compiles the model\n",
        "\n",
        "    Returns:\n",
        "        tf.keras.Model: compiled model\n",
        "    \"\"\"\n",
        "\n",
        "    model = create_uncompiled_model()\n",
        "\n",
        "    model.compile(loss = tf.keras.losses.Huber(),\n",
        "                  optimizer = tf.keras.optimizers.SGD(momentum=0.9),\n",
        "                  metrics=[\"mae\"])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "tB5E3fSL8_fC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_train, series_train, time_valid, series_valid = train_val_split(TIME, SERIES)\n",
        "series_train_windowed = create_windowed_dataset(series_train)\n",
        "\n",
        "# model\n",
        "uncompiled_model = create_uncompiled_model()"
      ],
      "metadata": {
        "id": "3EHqdFhN5SmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch = series_train_windowed.take(1)\n",
        "\n",
        "try:\n",
        "\tpredictions = uncompiled_model.predict(example_batch, verbose=False)\n",
        "except:\n",
        "\tprint(\"Your model is not compatible with the dataset you defined earlier. Check that the loss function and last layer are compatible with one another.\")\n",
        "else:\n",
        "\tprint(\"Your current architecture is compatible with the windowed dataset! :)\")\n",
        "\tprint(f\"predictions have shape: {predictions.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdZHW4188uLP",
        "outputId": "7319b6d0-16e6-449c-ab22-f31e6d6f67fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your current architecture is compatible with the windowed dataset! :)\n",
            "predictions have shape: (4, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()"
      ],
      "metadata": {
        "id": "qw0bUvqC871W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-8 * 10**(epoch / 20))\n",
        "\n",
        "history = model.fit(series_train_windowed, epochs=100, callbacks=[lr_schedule])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nGZ04qB9MGm",
        "outputId": "19e6ddbd-4229-4259-c63d-49f8d14a634f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 155500.3281 - mae: 155500.8281 - learning_rate: 1.0000e-08\n",
            "Epoch 2/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 154681.6250 - mae: 154682.1250 - learning_rate: 1.1220e-08\n",
            "Epoch 3/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 133035.1250 - mae: 133035.6250 - learning_rate: 1.2589e-08\n",
            "Epoch 4/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 121900.6484 - mae: 121901.1406 - learning_rate: 1.4125e-08\n",
            "Epoch 5/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 148272.6094 - mae: 148273.1094 - learning_rate: 1.5849e-08\n",
            "Epoch 6/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 129041.6172 - mae: 129042.1172 - learning_rate: 1.7783e-08\n",
            "Epoch 7/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 145566.1250 - mae: 145566.6250 - learning_rate: 1.9953e-08\n",
            "Epoch 8/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 169804.4688 - mae: 169804.9688 - learning_rate: 2.2387e-08\n",
            "Epoch 9/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 144703.6094 - mae: 144704.1094 - learning_rate: 2.5119e-08\n",
            "Epoch 10/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 139211.3125 - mae: 139211.8125 - learning_rate: 2.8184e-08\n",
            "Epoch 11/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 131394.6094 - mae: 131395.1094 - learning_rate: 3.1623e-08\n",
            "Epoch 12/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 144226.4375 - mae: 144226.9375 - learning_rate: 3.5481e-08\n",
            "Epoch 13/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 164057.9688 - mae: 164058.4688 - learning_rate: 3.9811e-08\n",
            "Epoch 14/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 130499.5078 - mae: 130500.0078 - learning_rate: 4.4668e-08\n",
            "Epoch 15/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 171654.1562 - mae: 171654.6562 - learning_rate: 5.0119e-08\n",
            "Epoch 16/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 132926.4375 - mae: 132926.9375 - learning_rate: 5.6234e-08\n",
            "Epoch 17/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 148242.7969 - mae: 148243.2969 - learning_rate: 6.3096e-08\n",
            "Epoch 18/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 152748.5469 - mae: 152749.0469 - learning_rate: 7.0795e-08\n",
            "Epoch 19/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 139891.4844 - mae: 139891.9844 - learning_rate: 7.9433e-08\n",
            "Epoch 20/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 141212.2500 - mae: 141212.7500 - learning_rate: 8.9125e-08\n",
            "Epoch 21/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 123959.5859 - mae: 123960.0859 - learning_rate: 1.0000e-07\n",
            "Epoch 22/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 134458.5625 - mae: 134459.0625 - learning_rate: 1.1220e-07\n",
            "Epoch 23/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 156748.7031 - mae: 156749.2031 - learning_rate: 1.2589e-07\n",
            "Epoch 24/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 134512.5469 - mae: 134513.0469 - learning_rate: 1.4125e-07\n",
            "Epoch 25/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 166280.9062 - mae: 166281.4062 - learning_rate: 1.5849e-07\n",
            "Epoch 26/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 135413.1406 - mae: 135413.6406 - learning_rate: 1.7783e-07\n",
            "Epoch 27/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 163727.0781 - mae: 163727.5781 - learning_rate: 1.9953e-07\n",
            "Epoch 28/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 170695.7188 - mae: 170696.2188 - learning_rate: 2.2387e-07\n",
            "Epoch 29/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 168924.0000 - mae: 168924.5000 - learning_rate: 2.5119e-07\n",
            "Epoch 30/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 148865.9844 - mae: 148866.4844 - learning_rate: 2.8184e-07\n",
            "Epoch 31/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 140404.8906 - mae: 140405.3906 - learning_rate: 3.1623e-07\n",
            "Epoch 32/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 149520.5000 - mae: 149521.0000 - learning_rate: 3.5481e-07\n",
            "Epoch 33/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 133983.3125 - mae: 133983.8125 - learning_rate: 3.9811e-07\n",
            "Epoch 34/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 150689.3594 - mae: 150689.8594 - learning_rate: 4.4668e-07\n",
            "Epoch 35/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 157825.0781 - mae: 157825.5781 - learning_rate: 5.0119e-07\n",
            "Epoch 36/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 162531.8750 - mae: 162532.3750 - learning_rate: 5.6234e-07\n",
            "Epoch 37/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 138303.8125 - mae: 138304.3125 - learning_rate: 6.3096e-07\n",
            "Epoch 38/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 140225.8750 - mae: 140226.3750 - learning_rate: 7.0795e-07\n",
            "Epoch 39/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 144092.1406 - mae: 144092.6406 - learning_rate: 7.9433e-07\n",
            "Epoch 40/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 164883.0000 - mae: 164883.5000 - learning_rate: 8.9125e-07\n",
            "Epoch 41/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 155797.0625 - mae: 155797.5625 - learning_rate: 1.0000e-06\n",
            "Epoch 42/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 151098.5469 - mae: 151099.0469 - learning_rate: 1.1220e-06\n",
            "Epoch 43/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 143476.9844 - mae: 143477.4844 - learning_rate: 1.2589e-06\n",
            "Epoch 44/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 151190.3750 - mae: 151190.8750 - learning_rate: 1.4125e-06\n",
            "Epoch 45/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 139981.2500 - mae: 139981.7500 - learning_rate: 1.5849e-06\n",
            "Epoch 46/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 128275.5312 - mae: 128276.0312 - learning_rate: 1.7783e-06\n",
            "Epoch 47/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 142542.9688 - mae: 142543.4688 - learning_rate: 1.9953e-06\n",
            "Epoch 48/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 157807.5000 - mae: 157808.0000 - learning_rate: 2.2387e-06\n",
            "Epoch 49/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 146557.2656 - mae: 146557.7656 - learning_rate: 2.5119e-06\n",
            "Epoch 50/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 150198.7188 - mae: 150199.2188 - learning_rate: 2.8184e-06\n",
            "Epoch 51/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 146525.8906 - mae: 146526.3906 - learning_rate: 3.1623e-06\n",
            "Epoch 52/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 148082.7969 - mae: 148083.2969 - learning_rate: 3.5481e-06\n",
            "Epoch 53/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 147880.0000 - mae: 147880.5000 - learning_rate: 3.9811e-06\n",
            "Epoch 54/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 166690.0312 - mae: 166690.5312 - learning_rate: 4.4668e-06\n",
            "Epoch 55/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 145689.5469 - mae: 145690.0469 - learning_rate: 5.0119e-06\n",
            "Epoch 56/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 146919.7969 - mae: 146920.2969 - learning_rate: 5.6234e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 138562.1250 - mae: 138562.6250 - learning_rate: 6.3096e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 165350.5000 - mae: 165351.0000 - learning_rate: 7.0795e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 147473.5781 - mae: 147474.0781 - learning_rate: 7.9433e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 142876.8594 - mae: 142877.3594 - learning_rate: 8.9125e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 148322.6875 - mae: 148323.1875 - learning_rate: 1.0000e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 134864.8750 - mae: 134865.3750 - learning_rate: 1.1220e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 162354.0469 - mae: 162354.5469 - learning_rate: 1.2589e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 163436.0469 - mae: 163436.5469 - learning_rate: 1.4125e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 163866.4375 - mae: 163866.9375 - learning_rate: 1.5849e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 137003.2969 - mae: 137003.7969 - learning_rate: 1.7783e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 126065.2812 - mae: 126065.7812 - learning_rate: 1.9953e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 147355.3281 - mae: 147355.8281 - learning_rate: 2.2387e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 130027.4688 - mae: 130027.9688 - learning_rate: 2.5119e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 144932.4219 - mae: 144932.9219 - learning_rate: 2.8184e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 153205.5625 - mae: 153206.0625 - learning_rate: 3.1623e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 157224.8281 - mae: 157225.3281 - learning_rate: 3.5481e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 160667.2344 - mae: 160667.7344 - learning_rate: 3.9811e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 134642.0625 - mae: 134642.5625 - learning_rate: 4.4668e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 155209.3438 - mae: 155209.8438 - learning_rate: 5.0119e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 143699.8281 - mae: 143700.3281 - learning_rate: 5.6234e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 156458.3750 - mae: 156458.8750 - learning_rate: 6.3096e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 134177.9062 - mae: 134178.4062 - learning_rate: 7.0795e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 175166.8906 - mae: 175167.3906 - learning_rate: 7.9433e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 160893.7812 - mae: 160894.2812 - learning_rate: 8.9125e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 168612.3438 - mae: 168612.8438 - learning_rate: 1.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 157156.2031 - mae: 157156.7031 - learning_rate: 1.1220e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 136076.5312 - mae: 136077.0312 - learning_rate: 1.2589e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 156403.5312 - mae: 156404.0312 - learning_rate: 1.4125e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 155001.6719 - mae: 155002.1719 - learning_rate: 1.5849e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 139575.1562 - mae: 139575.6562 - learning_rate: 1.7783e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 126896.3672 - mae: 126896.8672 - learning_rate: 1.9953e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 130969.8281 - mae: 130970.3281 - learning_rate: 2.2387e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 136862.0625 - mae: 136862.5625 - learning_rate: 2.5119e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 150141.8438 - mae: 150142.3438 - learning_rate: 2.8184e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 138301.7344 - mae: 138302.2344 - learning_rate: 3.1623e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 157187.3281 - mae: 157187.8281 - learning_rate: 3.5481e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 141332.5156 - mae: 141333.0156 - learning_rate: 3.9811e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 156072.0938 - mae: 156072.5938 - learning_rate: 4.4668e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 132166.2500 - mae: 132166.7500 - learning_rate: 5.0119e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 144760.8281 - mae: 144761.3281 - learning_rate: 5.6234e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 127179.4219 - mae: 127179.9219 - learning_rate: 6.3096e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 152656.6094 - mae: 152657.1094 - learning_rate: 7.0795e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 133022.7188 - mae: 133023.2188 - learning_rate: 7.9433e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 167188.2969 - mae: 167188.7969 - learning_rate: 8.9125e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xe-uVu8w9QG2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}